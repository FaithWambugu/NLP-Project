{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "befe2c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Load the libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66f4020b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\user\\Desktop\\crowdflower-brands-and-product-emotions\\judge-1377884607_tweet_product_company.csv\", encoding='ISO-8859-1')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ece0069c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "9089  Wave, buzz... RT @mention We interrupt your re...   \n",
       "9090  Google's Zeiger, a physician never reported po...   \n",
       "9091  Some Verizon iPhone customers complained their...   \n",
       "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "9088                            iPad   \n",
       "9089                             NaN   \n",
       "9090                             NaN   \n",
       "9091                             NaN   \n",
       "9092                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "9088                                   Positive emotion  \n",
       "9089                 No emotion toward brand or product  \n",
       "9090                 No emotion toward brand or product  \n",
       "9091                 No emotion toward brand or product  \n",
       "9092                 No emotion toward brand or product  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the last rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5458bcf4",
   "metadata": {},
   "source": [
    "The dataset values appear uniform from top to bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eed6d0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 9093 rows and 3 columns.\n"
     ]
    }
   ],
   "source": [
    "#Check shape\n",
    "print(f\"The dataset has {df.shape[0]} rows and {df.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeede767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#check for the dataset info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6caad69",
   "metadata": {},
   "source": [
    "Observation:\n",
    "- The dataset primarily consists of text data(object type) across all columns.\n",
    "- The column `emotion_in_tweet_is_directed_at` has many missing values only 3,291 out of 9,093 entries are non-null.\n",
    "-The `tweet-text` column has only 1 missing value, which will be handled during cleaning.\n",
    "- The dataset seems manageable in size as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05ff5937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_text                                               1\n",
      "emotion_in_tweet_is_directed_at                       5802\n",
      "is_there_an_emotion_directed_at_a_brand_or_product       0\n",
      "dtype: int64\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# Check missing values and duplicates\n",
    "print(df.isna().sum())\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edb50d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9092</td>\n",
       "      <td>3291</td>\n",
       "      <td>9093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>9065</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>RT @mention Marissa Mayer: Google Will Connect...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>946</td>\n",
       "      <td>5389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet_text  \\\n",
       "count                                                9092   \n",
       "unique                                               9065   \n",
       "top     RT @mention Marissa Mayer: Google Will Connect...   \n",
       "freq                                                    5   \n",
       "\n",
       "       emotion_in_tweet_is_directed_at  \\\n",
       "count                             3291   \n",
       "unique                               9   \n",
       "top                               iPad   \n",
       "freq                               946   \n",
       "\n",
       "       is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "count                                                9093  \n",
       "unique                                                  4  \n",
       "top                    No emotion toward brand or product  \n",
       "freq                                                 5389  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65262cd1",
   "metadata": {},
   "source": [
    "Observation:\n",
    "- The dataset is dominated by tweets without strong emotions towards a brand/product.\n",
    "-Only a subset of tweets approximately 37%(3,291 out of 9,093) tweets express an emotion directed at a brand.\n",
    "- The presence of duplicates and missing values confirms that data cleaning will be required before modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c7cbaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_text 9065\n",
      "emotion_in_tweet_is_directed_at 9\n",
      "is_there_an_emotion_directed_at_a_brand_or_product 4\n"
     ]
    }
   ],
   "source": [
    "# Check Unique values per column\n",
    "for col in df.columns:\n",
    "    print(col,df[col].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9048fa",
   "metadata": {},
   "source": [
    "Observation:\n",
    "\n",
    "The dataset contains;\n",
    "- 9,065 unique tweet texts, indicating minimal duplication in tweet content.\n",
    "- 9 unique values in the `emotion_in_tweet_is_directed_at` column, representing different brands or products mentioned in the tweets.\n",
    "- 4 unique values in the `is_there_an_emotion_directed_at_a_brand_or_product` column, showing the possible emotion labels assigned to each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4a5e13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_there_an_emotion_directed_at_a_brand_or_product\n",
       "No emotion toward brand or product    5389\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check value counts for key columns\n",
    "df[\"is_there_an_emotion_directed_at_a_brand_or_product\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af1da2f",
   "metadata": {},
   "source": [
    "- Most tweets(5,389) express no emotion toward a brand or product.\n",
    "- 2,978 tweets show positive emotion while 570 are negative\n",
    "- A small number(156) are uncertain(I can't tell) indicating a class imbalance, with \"No emotion\" being the dominant category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "225d220a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion_in_tweet_is_directed_at\n",
       "iPad                               946\n",
       "Apple                              661\n",
       "iPad or iPhone App                 470\n",
       "Google                             430\n",
       "iPhone                             297\n",
       "Other Google product or service    293\n",
       "Android App                         81\n",
       "Android                             78\n",
       "Other Apple product or service      35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"emotion_in_tweet_is_directed_at\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e076024",
   "metadata": {},
   "source": [
    "- The most mentioned products are ipad and Apple\n",
    "- Mentions of Google and its products are fewer but still significant. It shows that the dataset is skewed towards Apple-related tweets, which may influence model bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1fd108",
   "metadata": {},
   "source": [
    "### Column Renaming\n",
    "To simplify later analysis and code readability, we will rename the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf516a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after renaming: ['text', 'brand', 'sentiment']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>brand</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text               brand  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "\n",
       "          sentiment  \n",
       "0  Negative emotion  \n",
       "1  Positive emotion  \n",
       "2  Positive emotion  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the columns\n",
    "df = df.rename(columns={\n",
    "    'tweet_text': 'text',\n",
    "    'emotion_in_tweet_is_directed_at': 'brand',\n",
    "    'is_there_an_emotion_directed_at_a_brand_or_product': 'sentiment'\n",
    "})\n",
    "\n",
    "# Recheck column names\n",
    "print(\"Columns after renaming:\", df.columns.tolist())\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79325fc1",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c7474c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text            1\n",
       "brand        5802\n",
       "sentiment       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "621a8844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove tweet with no text/sentiment\n",
    "df = df.dropna(subset=[\"text\", \"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e823e8",
   "metadata": {},
   "source": [
    "Tweets missing a `brand` will be retained, as it still express sentiment that might be relevant for our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed035003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(22)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f580e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows after removal: 0\n",
      "New dataset shape: (9070, 3)\n"
     ]
    }
   ],
   "source": [
    "#Drop the duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "#we wil then confirm the removal\n",
    "print(\"Number of duplicate rows after removal:\", df.duplicated().sum())\n",
    "print(\"New dataset shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3c54780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dataset\n",
    "df.to_csv(\"clean_apple_google_tweets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c4ac66",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "#### Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8c9796",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4eeff1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>brand</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text               brand  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "          sentiment  \n",
       "0  Negative emotion  \n",
       "1  Positive emotion  \n",
       "2  Positive emotion  \n",
       "3  Negative emotion  \n",
       "4  Positive emotion  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the clean dataset\n",
    "df = pd.read_csv(\"clean_apple_google_tweets.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d70cab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercased: 0       .@wesley83 i have a 3g iphone. after 3 hrs twe...\n",
      "1       @jessedee know about @fludapp ? awesome ipad/i...\n",
      "2       @swonderlin can not wait for #ipad 2 also. the...\n",
      "3       @sxsw i hope this year's festival isn't as cra...\n",
      "4       @sxtxstate great stuff on fri #sxsw: marissa m...\n",
      "                              ...                        \n",
      "9065                        ipad everywhere. #sxsw {link}\n",
      "9066    wave, buzz... rt @mention we interrupt your re...\n",
      "9067    google's zeiger, a physician never reported po...\n",
      "9068    some verizon iphone customers complained their...\n",
      "9069    ï¡ïàü_êîò£áââ_£â_ûârt @...\n",
      "Name: text, Length: 9070, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Text preprocessing\n",
    "\n",
    "# Convert to lowercase\n",
    "df[\"text\"] = df[\"text\"].str.lower()\n",
    "print(\"Lowercased:\", df[\"text\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72966ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>brand</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 i have a 3g iphone. after 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>i have a g iphone after hrs tweeting at it was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee know about @fludapp ? awesome ipad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>know about awesome ipadiphone app that youll l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin can not wait for #ipad 2 also. the...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>can not wait for also they should sale them do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw i hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>i hope this years festival isnt as crashy as t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on fri #sxsw: marissa m...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>great stuff on fri marissa mayer google tim or...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text               brand  \\\n",
       "0  .@wesley83 i have a 3g iphone. after 3 hrs twe...              iPhone   \n",
       "1  @jessedee know about @fludapp ? awesome ipad/i...  iPad or iPhone App   \n",
       "2  @swonderlin can not wait for #ipad 2 also. the...                iPad   \n",
       "3  @sxsw i hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on fri #sxsw: marissa m...              Google   \n",
       "\n",
       "          sentiment                                         clean_text  \n",
       "0  Negative emotion  i have a g iphone after hrs tweeting at it was...  \n",
       "1  Positive emotion  know about awesome ipadiphone app that youll l...  \n",
       "2  Positive emotion  can not wait for also they should sale them do...  \n",
       "3  Negative emotion  i hope this years festival isnt as crashy as t...  \n",
       "4  Positive emotion  great stuff on fri marissa mayer google tim or...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove URLs, mentions, Hashtags, Punctuation, Digits, Extraspaces\n",
    "def clean_text(text):\n",
    "    # remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\t\t# remove mentions\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # remove hashtags\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    # remove punctuation\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7986e0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>brand</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 i have a 3g iphone. after 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>g iphone hrs tweeting dead need upgrade plugin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee know about @fludapp ? awesome ipad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>know awesome ipadiphone app youll likely appre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin can not wait for #ipad 2 also. the...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>wait also sale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text               brand  \\\n",
       "0  .@wesley83 i have a 3g iphone. after 3 hrs twe...              iPhone   \n",
       "1  @jessedee know about @fludapp ? awesome ipad/i...  iPad or iPhone App   \n",
       "2  @swonderlin can not wait for #ipad 2 also. the...                iPad   \n",
       "\n",
       "          sentiment                                         clean_text  \n",
       "0  Negative emotion  g iphone hrs tweeting dead need upgrade plugin...  \n",
       "1  Positive emotion  know awesome ipadiphone app youll likely appre...  \n",
       "2  Positive emotion                                     wait also sale  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing stopwords i.e common words that do not carry much meaning\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df[\"clean_text\"] = df[\"clean_text\"].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f34520fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>brand</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 i have a 3g iphone. after 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>g iphone hr tweeting dead need upgrade plugin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee know about @fludapp ? awesome ipad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>know awesome ipadiphone app youll likely appre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin can not wait for #ipad 2 also. the...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>wait also sale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text               brand  \\\n",
       "0  .@wesley83 i have a 3g iphone. after 3 hrs twe...              iPhone   \n",
       "1  @jessedee know about @fludapp ? awesome ipad/i...  iPad or iPhone App   \n",
       "2  @swonderlin can not wait for #ipad 2 also. the...                iPad   \n",
       "\n",
       "          sentiment                                         clean_text  \n",
       "0  Negative emotion  g iphone hr tweeting dead need upgrade plugin ...  \n",
       "1  Positive emotion  know awesome ipadiphone app youll likely appre...  \n",
       "2  Positive emotion                                     wait also sale  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization to reduce words to their base form to ensure uniformity\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df[\"clean_text\"] = df[\"clean_text\"].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9767274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g iphone hr tweeting dead need upgrade plugin ...</td>\n",
       "      <td>[g, iphone, hr, tweeting, dead, need, upgrade,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>know awesome ipadiphone app youll likely appre...</td>\n",
       "      <td>[know, awesome, ipadiphone, app, youll, likely...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wait also sale</td>\n",
       "      <td>[wait, also, sale]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hope year festival isnt crashy year iphone app</td>\n",
       "      <td>[hope, year, festival, isnt, crashy, year, iph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great stuff fri marissa mayer google tim oreil...</td>\n",
       "      <td>[great, stuff, fri, marissa, mayer, google, ti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  \\\n",
       "0  g iphone hr tweeting dead need upgrade plugin ...   \n",
       "1  know awesome ipadiphone app youll likely appre...   \n",
       "2                                     wait also sale   \n",
       "3     hope year festival isnt crashy year iphone app   \n",
       "4  great stuff fri marissa mayer google tim oreil...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [g, iphone, hr, tweeting, dead, need, upgrade,...  \n",
       "1  [know, awesome, ipadiphone, app, youll, likely...  \n",
       "2                                 [wait, also, sale]  \n",
       "3  [hope, year, festival, isnt, crashy, year, iph...  \n",
       "4  [great, stuff, fri, marissa, mayer, google, ti...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenization to split each tweet into individual word-tokens to be used in feature extraction \n",
    "df[\"tokens\"] = df[\"clean_text\"].apply(word_tokenize)\n",
    "df[[\"clean_text\", \"tokens\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200561cf",
   "metadata": {},
   "source": [
    "#### Feature Extraction(Converting Text to Numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a1b8780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF matrix: (9070, 8388)\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "TF-IDF Vocabulary: ['aapl' 'aaron' 'ab' ... 'zuckerberg' 'zynga' 'zzzs']\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Vocabulary size: 8388\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "TF-IDF Representation: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Using TF-IDF(Term Frequency-Inverse Document Frequency)\n",
    "\n",
    "# initialize the vectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# fit and transform cleaned text\n",
    "X = tfidf.fit_transform(df[\"clean_text\"])\n",
    "\n",
    "print(\"Shape of TF-IDF matrix:\" , X.shape)\n",
    "print(\"-------\"*15)\n",
    "print(\"TF-IDF Vocabulary:\", tfidf.get_feature_names_out())\n",
    "print(\"-------\"*15)\n",
    "print(\"Vocabulary size:\", len(tfidf.get_feature_names_out()))\n",
    "print(\"-------\"*15)\n",
    "print(\"TF-IDF Representation:\", X.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba9f2a6",
   "metadata": {},
   "source": [
    "TF-IDF assigns higher weight to words that are important in a specific tweet but rare across all tweets. It also helps the model focus on meaningful words that carry sentiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0abcc4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Bag-of-Words matrix: (9070, 8388)\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Bag-of-Words Vocabulary: ['aapl' 'aaron' 'ab' ... 'zuckerberg' 'zynga' 'zzzs']\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Vocabulary size: 8388\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Bag-of-Words Representation: [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Using CountVectorizer or Bag of Words(BoW)\n",
    "\n",
    "#Initialize the vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "#Fit and transform cleaned text\n",
    "X_bow = vectorizer.fit_transform(df[\"clean_text\"])\n",
    "\n",
    "print(\"Shape of Bag-of-Words matrix:\", X_bow.shape)\n",
    "print(\"-------\"*15)\n",
    "print(\"Bag-of-Words Vocabulary:\", vectorizer.get_feature_names_out())\n",
    "print(\"-------\"*15)\n",
    "print(\"Vocabulary size:\", len(vectorizer.get_feature_names_out()))\n",
    "print(\"-------\"*15)\n",
    "print(\"Bag-of-Words Representation:\", X_bow.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636a7594",
   "metadata": {},
   "source": [
    "Bag-of-Words (CountVectorizer) captures the raw frequency of words in each tweet, and is useful as a baseline model providing a straightforward representation of text.\n",
    "\n",
    "Using both approches allows comparison of feature representations and model performance. While TF-IDF often yields better results for sentiment classification, BoW provides a simple, interpretable baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842857ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
